# -*- coding: utf-8 -*-
"""Iris Flower Classification.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1nQLrrNQytEKryp1lQ8-1TugKeIgimFRx
"""

# Commented out IPython magic to ensure Python compatibility.
import numpy as np
import pandas as pd
import seaborn as sns
import matplotlib.pyplot as plt
from sklearn.model_selection import train_test_split, cross_val_score, GridSearchCV
from sklearn.preprocessing import StandardScaler, LabelEncoder
from sklearn.svm import SVC
from sklearn.linear_model import LogisticRegression
from sklearn.tree import DecisionTreeClassifier
from sklearn.metrics import accuracy_score, classification_report
from tensorflow.keras.models import Sequential
from tensorflow.keras.layers import Dense

# %matplotlib inline

# Load dataset
columns = ['Sepal length', 'Sepal width', 'Petal length', 'Petal width', 'Class_labels']
df = pd.read_csv('/content/drive/MyDrive/iris.csv', names=columns)
df.drop(index=0, inplace=True)
df.reset_index(drop=True, inplace=True)
df

numeric_columns = ['Sepal length', 'Sepal width', 'Petal length', 'Petal width']
df[numeric_columns] = df[numeric_columns].apply(pd.to_numeric, errors='coerce')

df.describe()

df.isna().sum()

df.info()

df.shape

sns.pairplot(df, hue='Class_labels')

data = df.values

x = data[:, 0:4]
y = data[:, 4]
print(y)

# Train-test split
x_train, x_test, y_train, y_test = train_test_split(x, y, test_size=0.2)

# Standardize data
scaler = StandardScaler()
x_train = scaler.fit_transform(x_train)
x_test = scaler.transform(x_test)

"""MODEL1: SVM"""

# Model 1: SVM
model_svc = SVC()
model_svc.fit(x_train, y_train)
prediction1 = model_svc.predict(x_test)
print("SVM Accuracy:", accuracy_score(y_test, prediction1) * 100)
for i in range(len(prediction1)):
  print(y_test[i], ' ', prediction1[i])

"""MODEL2: LOGISTIC REGRESSION"""

# Model 2: Logistic Regression
model_lr = LogisticRegression()
model_lr.fit(x_train, y_train)
prediction2 = model_lr.predict(x_test)
print("Logistic Regression Accuracy:", accuracy_score(y_test, prediction2) * 100)
for i in range(len(prediction2)):
  print(y_test[i], ' ', prediction2[i])

"""MODEL3: DECISION TREE CLASSIFIER"""

# Model 3: Decision Tree Classifier
model_dt = DecisionTreeClassifier()
model_dt.fit(x_train, y_train)
prediction3 = model_dt.predict(x_test)
print("Decision Tree Accuracy:", accuracy_score(y_test, prediction3) * 100)
for i in range(len(prediction1)):
  print(y_test[i],' ', prediction3[i])

# Print classification report
print(classification_report(y_test, prediction2))

x_new = np.array([[3,2,1,0.2],[4.9,2.2,3.8,1.1],[5.3,2.5,4.6,1.9]])
prediction = model_svc.predict(x_new)
print("Prediction of Spices: {}".format(prediction))

data = df.values
x = data[:, 0:4].astype(float)
y = data[:, 4]

# Encode class labels
encoder = LabelEncoder()
y_encoded = encoder.fit_transform(y)

x_train, x_test, y_train, y_test = train_test_split(x, y_encoded, test_size=0.2, random_state=42)

# Build a simple Keras model
model = Sequential([
    Dense(8, input_shape=(4,), activation='relu'),
    Dense(8, activation='relu'),
    Dense(3, activation='softmax')  # 3 output classes
])

model.compile(optimizer='adam', loss='sparse_categorical_crossentropy', metrics=['accuracy'])

model.fit(x_train, y_train, epochs=50, batch_size=5, verbose=1)

# Save the model
model.save('iris_keras_model.h5')

